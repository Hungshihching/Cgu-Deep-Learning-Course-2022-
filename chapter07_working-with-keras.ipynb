{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
    "\n",
    "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
    "\n",
    "This notebook was generated for TensorFlow 2.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Working with Keras: A deep dive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## A spectrum of workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Different ways to build Keras models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The Sequential model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The `Sequential` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-30 18:35:33.753823: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-30 18:35:41.805337: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Incrementally building a Sequential model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Calling a model for the first time to build it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_2/kernel:0' shape=(3, 64) dtype=float32, numpy=\n",
       " array([[ 0.00826055,  0.01038662, -0.00529355, -0.22402701,  0.26233   ,\n",
       "          0.21194142, -0.04200074, -0.08394368, -0.16915427, -0.23064533,\n",
       "         -0.01163542, -0.18532965, -0.0254246 ,  0.01267588, -0.19763395,\n",
       "         -0.2555744 ,  0.2802739 , -0.2741754 ,  0.02299526,  0.01975033,\n",
       "          0.2035644 ,  0.09552029, -0.08828823,  0.29623288,  0.13393334,\n",
       "         -0.29113263,  0.23519486,  0.23809695, -0.2555107 , -0.00432158,\n",
       "          0.112418  ,  0.1469954 ,  0.10011777,  0.2602507 , -0.18807012,\n",
       "         -0.1014868 ,  0.17487034, -0.2469326 , -0.19958523,  0.07097322,\n",
       "         -0.08683766,  0.02373615, -0.16769849, -0.21569991,  0.10809508,\n",
       "         -0.2885524 , -0.16086555, -0.03239086, -0.0577683 , -0.03298876,\n",
       "         -0.1376705 , -0.0105612 ,  0.16550526, -0.00461662,  0.00171426,\n",
       "          0.20890385, -0.0233573 , -0.19350144, -0.2715508 , -0.2559295 ,\n",
       "         -0.22676688, -0.2098273 , -0.23295513, -0.03829959],\n",
       "        [ 0.16382432,  0.24025524,  0.02520898,  0.05555639, -0.07010156,\n",
       "          0.27988285,  0.11823562,  0.2689185 ,  0.15168813,  0.02209514,\n",
       "          0.02237141, -0.02236983, -0.28235874, -0.00979629,  0.28223115,\n",
       "          0.15070331, -0.00717604, -0.1301589 , -0.03110826, -0.24165803,\n",
       "         -0.1296589 ,  0.13229641,  0.00083154,  0.20023   , -0.17235199,\n",
       "         -0.12834975, -0.22655348, -0.22284284,  0.13301566, -0.03302309,\n",
       "          0.03556213, -0.05879492,  0.15462863, -0.17376666,  0.07500347,\n",
       "         -0.19065231, -0.2408971 ,  0.2896787 ,  0.04488704,  0.28728873,\n",
       "          0.22745067,  0.1270015 ,  0.28075808, -0.2257643 ,  0.27005613,\n",
       "          0.27326244,  0.05721414, -0.27519518,  0.02207232,  0.12140352,\n",
       "          0.23955083,  0.07576618, -0.1594877 ,  0.20569623,  0.11365166,\n",
       "         -0.07904346,  0.09106794, -0.00354603, -0.07029969,  0.19598404,\n",
       "          0.13504785, -0.20872034,  0.05409876,  0.21084338],\n",
       "        [-0.29327175, -0.29336035, -0.18447512, -0.28498873,  0.03468376,\n",
       "          0.13594398, -0.21797746,  0.18056637,  0.10543916,  0.07481563,\n",
       "          0.22134793, -0.24414413,  0.23155594, -0.20774603, -0.2108823 ,\n",
       "         -0.26423228, -0.00556225,  0.19978815,  0.2503121 , -0.19421378,\n",
       "         -0.04198509, -0.2943842 , -0.01882631, -0.17646459,  0.14023194,\n",
       "          0.16758949, -0.13456018,  0.08637598,  0.16655481,  0.19672462,\n",
       "          0.08968201, -0.09669118, -0.24116752, -0.00951675,  0.29298812,\n",
       "          0.24962163, -0.10900204,  0.24957609, -0.19748905,  0.29597968,\n",
       "          0.03245294,  0.07614896, -0.05569224,  0.08641371, -0.07407069,\n",
       "          0.16367242,  0.24577177, -0.24418843, -0.22167931,  0.19254574,\n",
       "          0.06169912, -0.25531194, -0.08111282,  0.18376544, -0.00659999,\n",
       "         -0.00980306, -0.17348912,  0.16986203, -0.08763069,  0.21807271,\n",
       "          0.10762069, -0.01308703,  0.21787429, -0.08821975]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/kernel:0' shape=(64, 10) dtype=float32, numpy=\n",
       " array([[ 0.26300368,  0.00648198,  0.02752379,  0.10915396,  0.23029444,\n",
       "         -0.07150573, -0.23206711,  0.21861681,  0.1259844 ,  0.07436886],\n",
       "        [ 0.08084041, -0.02988777, -0.21006277, -0.25311917,  0.13986656,\n",
       "         -0.02802229, -0.06210084, -0.14176996,  0.04933104,  0.17777649],\n",
       "        [-0.21261662, -0.1672304 , -0.09070869,  0.25792488, -0.25452048,\n",
       "         -0.17705184, -0.12754211,  0.21478045, -0.1385252 , -0.27326342],\n",
       "        [ 0.13288662,  0.15079162, -0.26070896, -0.20853302, -0.13709728,\n",
       "          0.18849218,  0.21754745,  0.04492742,  0.10579717, -0.24587947],\n",
       "        [-0.2382708 ,  0.23523334, -0.03199631, -0.11045219, -0.10358888,\n",
       "         -0.1351839 ,  0.24804553, -0.00059524, -0.01707768, -0.17105663],\n",
       "        [-0.09319723, -0.03934368, -0.27852556,  0.09425616,  0.24426731,\n",
       "          0.20237818,  0.24282482, -0.24077334, -0.02851611, -0.07510372],\n",
       "        [-0.19792162, -0.18142946, -0.04858562, -0.12390454,  0.09251338,\n",
       "          0.2524785 ,  0.04473549, -0.11475886,  0.150803  ,  0.07760006],\n",
       "        [ 0.08291373,  0.19978559,  0.24427792,  0.0622232 ,  0.00552279,\n",
       "         -0.13795833, -0.04240352,  0.07977822, -0.24564342,  0.07001826],\n",
       "        [-0.05311804, -0.18280028,  0.12817538, -0.09564409, -0.16264606,\n",
       "         -0.19201079,  0.1138778 ,  0.06834617,  0.09881458, -0.25701213],\n",
       "        [ 0.1230152 ,  0.17418638, -0.1258753 , -0.21730883, -0.01571402,\n",
       "         -0.19841205, -0.05244954,  0.02313524, -0.04269998, -0.02933902],\n",
       "        [ 0.15052229, -0.20325845, -0.20971212, -0.10681999,  0.04117262,\n",
       "         -0.09468135,  0.2189503 , -0.00915322,  0.21991989,  0.18630356],\n",
       "        [-0.15137374, -0.24317268,  0.06040999,  0.12953663, -0.24535027,\n",
       "          0.03847274, -0.17795354,  0.18600905, -0.06225787, -0.08908838],\n",
       "        [-0.02978849,  0.23988292,  0.22630838, -0.02094087, -0.10426207,\n",
       "          0.05647916,  0.05276787, -0.1185576 ,  0.25146553,  0.26967117],\n",
       "        [-0.13566008,  0.01372236, -0.08969022,  0.04740763, -0.1789452 ,\n",
       "         -0.0185968 ,  0.00508326, -0.21031809,  0.15722594, -0.23128088],\n",
       "        [-0.05207559,  0.2812995 , -0.245953  ,  0.21142966, -0.15440975,\n",
       "          0.196765  ,  0.17090964, -0.01785502,  0.18743989, -0.23999077],\n",
       "        [ 0.06536224,  0.23695388, -0.217854  ,  0.12887314,  0.21921232,\n",
       "          0.21036834, -0.27958226,  0.19405541,  0.23508534,  0.22118512],\n",
       "        [ 0.10184351, -0.03087521,  0.10506281, -0.11973195,  0.02509025,\n",
       "         -0.24415265,  0.22140118,  0.03770986, -0.19068715,  0.19799119],\n",
       "        [ 0.11818284, -0.2652941 , -0.28056917,  0.18818817, -0.20659024,\n",
       "          0.00867173, -0.00771451,  0.28170094, -0.2020972 , -0.06693855],\n",
       "        [-0.05499721,  0.12028402, -0.07496026, -0.19283544,  0.15638363,\n",
       "         -0.00551924,  0.24974343, -0.26796156,  0.13336569, -0.02239823],\n",
       "        [ 0.11226591, -0.1327471 ,  0.18783072, -0.01376268, -0.20754734,\n",
       "          0.00405908,  0.20159483,  0.00355414, -0.11251867,  0.23524377],\n",
       "        [ 0.060783  ,  0.12091905,  0.0095962 , -0.1925146 ,  0.02754539,\n",
       "          0.12422132, -0.25581247, -0.1930505 ,  0.06241736, -0.22796355],\n",
       "        [-0.06844908, -0.05264275,  0.10617137, -0.01353362, -0.215045  ,\n",
       "         -0.08371945, -0.04330854, -0.25212675,  0.15009472,  0.25566825],\n",
       "        [-0.19996297, -0.22847924, -0.05034518, -0.25464788, -0.18857723,\n",
       "         -0.13694121,  0.01146904, -0.14375205,  0.27297756,  0.20347849],\n",
       "        [ 0.22979268, -0.17487994,  0.05020764, -0.26009423, -0.21707061,\n",
       "          0.02462649,  0.02867228,  0.19728753,  0.09322289,  0.23928568],\n",
       "        [ 0.06565022, -0.2797452 ,  0.2370461 , -0.28126103,  0.18819943,\n",
       "          0.28065726, -0.07864283,  0.11348778,  0.07518646,  0.20699933],\n",
       "        [-0.05547881,  0.16345358, -0.21591052,  0.00314876, -0.15222473,\n",
       "          0.19301051, -0.12360515,  0.00035602, -0.22790252,  0.25699487],\n",
       "        [-0.12507509,  0.17994466,  0.16341755, -0.10425894, -0.27168167,\n",
       "          0.2029697 ,  0.24458137, -0.17928573, -0.09206505,  0.07280213],\n",
       "        [-0.18753602,  0.15377322,  0.05000919,  0.09581354, -0.09273931,\n",
       "         -0.08520934,  0.22273543, -0.26830146,  0.04805928, -0.27379063],\n",
       "        [ 0.02736032, -0.10030237, -0.19299912,  0.18630451,  0.26499543,\n",
       "         -0.26267502,  0.10574543, -0.10842183, -0.13615675, -0.21352273],\n",
       "        [-0.23434377, -0.21416286,  0.21982506, -0.15641166,  0.21617332,\n",
       "          0.18727803,  0.01737133, -0.19182436, -0.17526351,  0.20464903],\n",
       "        [ 0.04745135, -0.1430995 , -0.27008927, -0.05662383,  0.10080013,\n",
       "         -0.25407544,  0.28061518,  0.2459422 ,  0.14487508,  0.2132498 ],\n",
       "        [-0.27687144, -0.10659547,  0.1649183 ,  0.26286742,  0.06812206,\n",
       "         -0.06221877, -0.0181016 ,  0.20590055, -0.14630915,  0.0195961 ],\n",
       "        [ 0.26735714,  0.26042655,  0.09805477, -0.13427351, -0.25937495,\n",
       "         -0.24598762,  0.24825898, -0.20121424, -0.0012736 , -0.05991685],\n",
       "        [-0.15302876, -0.05950946,  0.1237084 , -0.11742121,  0.06872919,\n",
       "         -0.18013155, -0.2580273 ,  0.25112948,  0.21326298,  0.2821528 ],\n",
       "        [ 0.17499071,  0.01369682, -0.18338656,  0.0614517 , -0.02278671,\n",
       "          0.12913376,  0.01886421,  0.04685342,  0.01620838,  0.06973872],\n",
       "        [ 0.02888668, -0.01522133, -0.19968674, -0.22135103,  0.07259324,\n",
       "         -0.12204106,  0.04496965,  0.03892991, -0.15943015, -0.24946007],\n",
       "        [-0.04167777, -0.1649849 ,  0.13804999, -0.24441035, -0.12950274,\n",
       "          0.21672657,  0.2574735 , -0.13157567,  0.09735823,  0.27659264],\n",
       "        [-0.23955473,  0.08002818,  0.15629658,  0.21588191, -0.08603317,\n",
       "         -0.01275644, -0.12590972, -0.06077789,  0.2811713 ,  0.22329888],\n",
       "        [ 0.01220095, -0.19997147, -0.22245517, -0.07893883,  0.06870216,\n",
       "         -0.23915099, -0.27613395,  0.17872334, -0.2105995 ,  0.20855018],\n",
       "        [-0.05850144,  0.09876102, -0.22555111,  0.19050115,  0.18011472,\n",
       "         -0.25175214, -0.08218257, -0.19873792,  0.13763681,  0.07451227],\n",
       "        [-0.14008652, -0.0438448 , -0.26942977, -0.18231651,  0.15260214,\n",
       "          0.02677497, -0.25776142,  0.14702734, -0.14970578,  0.0672439 ],\n",
       "        [-0.03201512,  0.06869105,  0.23057708, -0.06690101, -0.0661359 ,\n",
       "         -0.12705323,  0.28430745,  0.27046522, -0.13624209,  0.22040626],\n",
       "        [-0.03719357, -0.17526771,  0.13399503,  0.06276059, -0.2829738 ,\n",
       "          0.22577623,  0.08099043,  0.01503274,  0.06989479,  0.10216415],\n",
       "        [ 0.23673686, -0.0501684 , -0.09910895, -0.06916803,  0.09830201,\n",
       "          0.21044245, -0.08505611, -0.22125258, -0.15670535,  0.18566221],\n",
       "        [-0.01317361, -0.18972917,  0.16078025, -0.19145484, -0.14451587,\n",
       "         -0.21161097, -0.2378875 ,  0.25747797,  0.22275689,  0.23309937],\n",
       "        [ 0.07726163, -0.19627476, -0.04645874, -0.13345708, -0.08952661,\n",
       "          0.17231134,  0.16006279, -0.04805873,  0.02848339, -0.24735178],\n",
       "        [-0.0467252 , -0.07886124,  0.11880389,  0.09381965, -0.26568013,\n",
       "         -0.24470568,  0.22321472, -0.21189563, -0.11883628,  0.2832913 ],\n",
       "        [-0.24877556, -0.115099  ,  0.05050153,  0.17665046,  0.25249317,\n",
       "          0.27914163, -0.1380197 ,  0.2222968 ,  0.05088821,  0.19196239],\n",
       "        [ 0.13775337, -0.16576128, -0.0536399 , -0.01715007, -0.15585579,\n",
       "         -0.16459224,  0.02576262,  0.21884117, -0.17662142,  0.2552128 ],\n",
       "        [-0.07675022, -0.22654155, -0.23692939, -0.22565295, -0.22300975,\n",
       "          0.12123379, -0.22576055,  0.22355041, -0.24187374,  0.11494908],\n",
       "        [ 0.09099445,  0.13020778,  0.28037694, -0.17258854, -0.25671655,\n",
       "         -0.14443582,  0.21759465,  0.17196152,  0.05670854, -0.19722942],\n",
       "        [-0.05846763,  0.23343977,  0.2642462 , -0.03642473,  0.14003986,\n",
       "         -0.019371  ,  0.01159388,  0.08784473, -0.01415658, -0.15240173],\n",
       "        [-0.17062695, -0.18870458, -0.06027211,  0.21988025,  0.0598276 ,\n",
       "         -0.09324944,  0.25249287, -0.03007397, -0.00541729, -0.1447898 ],\n",
       "        [-0.16593215, -0.2843761 , -0.20221493, -0.05301036,  0.2837765 ,\n",
       "          0.13361344, -0.08340226,  0.19687116,  0.19576403, -0.23735397],\n",
       "        [ 0.28274617, -0.18635929,  0.19547176, -0.10879196, -0.1306517 ,\n",
       "         -0.16424558,  0.05941895,  0.12174451,  0.02506471, -0.06810312],\n",
       "        [ 0.01545691, -0.20789921, -0.28210068,  0.27336577, -0.02270123,\n",
       "         -0.0154269 ,  0.01947677, -0.262817  , -0.02006793, -0.10238126],\n",
       "        [-0.21422748,  0.20613417,  0.12594631, -0.02188656, -0.10920024,\n",
       "         -0.13715486, -0.03470394,  0.23053995, -0.11592452,  0.25557712],\n",
       "        [ 0.09527633,  0.03214505,  0.15850794,  0.22426412,  0.04792532,\n",
       "         -0.02426463,  0.02295452,  0.00239256,  0.00454891,  0.22907487],\n",
       "        [ 0.15983272, -0.1641318 ,  0.2826124 , -0.1355617 ,  0.06056553,\n",
       "          0.02155581,  0.26987675,  0.21568045,  0.04396552,  0.20162877],\n",
       "        [-0.16199167,  0.223326  ,  0.22614822,  0.03956807,  0.07413602,\n",
       "         -0.05597149,  0.25174555, -0.09033319, -0.18633723, -0.17507328],\n",
       "        [-0.11048342,  0.15950638,  0.03028673,  0.05424064,  0.12480834,\n",
       "          0.04032761, -0.06139758, -0.08088738, -0.08702721,  0.25754187],\n",
       "        [ 0.27386782,  0.19094345,  0.05866525,  0.22175375, -0.05628765,\n",
       "          0.2657567 ,  0.16569394,  0.01561931,  0.12928048,  0.12564734],\n",
       "        [-0.18565142,  0.21833792,  0.00877562, -0.19215518,  0.15171394,\n",
       "         -0.01685035, -0.05785446, -0.24671295, -0.26702997, -0.16575891],\n",
       "        [-0.22643374,  0.03639084, -0.11638156,  0.25922427, -0.09297483,\n",
       "         -0.14966682,  0.2370592 ,  0.16713774,  0.00944018,  0.14100742]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_3/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build(input_shape=(None, 3))\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The summary method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Naming models and layers with the `name` argument**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_example_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_first_layer (Dense)      (None, 64)                256       \n",
      "                                                                 \n",
      " my_last_layer (Dense)       (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(name=\"my_example_model\")\n",
    "model.add(layers.Dense(64, activation=\"relu\", name=\"my_first_layer\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\", name=\"my_last_layer\"))\n",
    "model.build((None, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Specifying the input shape of your model in advance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(3,)))\n",
    "model.add(layers.Dense(64, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_28 (Dense)            (None, 64)                256       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256\n",
      "Trainable params: 256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_28 (Dense)            (None, 64)                256       \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### A simple example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple Functional model with two `Dense` layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = layers.Dense(20, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 3])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = layers.Dense(64, activation=\"relu\")(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 64])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_input (InputLayer)       [(None, 3)]               0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 64)                256       \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Multi-input, multi-output models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A multi-input, multi-output Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 10000\n",
    "num_tags = 100\n",
    "num_departments = 4\n",
    "\n",
    "title = keras.Input(shape=(vocabulary_size,), name=\"title\")\n",
    "text_body = keras.Input(shape=(vocabulary_size,), name=\"text_body\")\n",
    "tags = keras.Input(shape=(num_tags,), name=\"tags\")\n",
    "\n",
    "features = layers.Concatenate()([title, text_body, tags])\n",
    "features = layers.Dense(64, activation=\"relu\")(features)\n",
    "\n",
    "priority = layers.Dense(1, activation=\"sigmoid\", name=\"priority\")(features)\n",
    "department = layers.Dense(\n",
    "    num_departments, activation=\"softmax\", name=\"department\")(features)\n",
    "\n",
    "model = keras.Model(inputs=[title, text_body, tags], outputs=[priority, department])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Training a multi-input, multi-output model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a model by providing lists of input & target arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 13ms/step - loss: 29.4253 - priority_loss: 0.3485 - department_loss: 29.0769 - priority_mean_absolute_error: 0.5144 - department_accuracy: 0.2484\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 31.0509 - priority_loss: 0.3517 - department_loss: 30.6992 - priority_mean_absolute_error: 0.5168 - department_accuracy: 0.0664\n",
      "40/40 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 1280\n",
    "\n",
    "title_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "text_body_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "tags_data = np.random.randint(0, 2, size=(num_samples, num_tags))\n",
    "\n",
    "priority_data = np.random.random(size=(num_samples, 1))\n",
    "department_data = np.random.randint(0, 2, size=(num_samples, num_departments))\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit([title_data, text_body_data, tags_data],\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate([title_data, text_body_data, tags_data],\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict([title_data, text_body_data, tags_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a model by providing dicts of input & target arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 13ms/step - loss: 35.3629 - priority_loss: 0.3517 - department_loss: 35.0112 - priority_mean_absolute_error: 0.5168 - department_accuracy: 0.2523\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 43.2578 - priority_loss: 0.3517 - department_loss: 42.9060 - priority_mean_absolute_error: 0.5168 - department_accuracy: 0.0664\n",
      "40/40 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss={\"priority\": \"mean_squared_error\", \"department\": \"categorical_crossentropy\"},\n",
    "              metrics={\"priority\": [\"mean_absolute_error\"], \"department\": [\"accuracy\"]})\n",
    "model.fit({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "          {\"priority\": priority_data, \"department\": department_data},\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "               {\"priority\": priority_data, \"department\": department_data})\n",
    "priority_preds, department_preds = model.predict(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The power of the Functional API: Access to layer connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"ticket_classifier.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"ticket_classifier_with_shape_info.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Retrieving the inputs or outputs of a layer in a Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x7f7e4e0cac70>,\n",
       " <keras.engine.input_layer.InputLayer at 0x7f7e4e0ca730>,\n",
       " <keras.engine.input_layer.InputLayer at 0x7f7e4e0ca5b0>,\n",
       " <keras.layers.merging.concatenate.Concatenate at 0x7f7e4e0c8b20>,\n",
       " <keras.layers.core.dense.Dense at 0x7f7e8ae93790>,\n",
       " <keras.layers.core.dense.Dense at 0x7f7e4eaa9880>,\n",
       " <keras.layers.core.dense.Dense at 0x7f7e8ae8aa00>]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'title')>,\n",
       " <KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'text_body')>,\n",
       " <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'tags')>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 20100) dtype=float32 (created by layer 'concatenate_2')>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a new model by reusing intermediate layer outputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = model.layers[4].output\n",
    "difficulty = layers.Dense(3, activation=\"softmax\", name=\"difficulty\")(features)\n",
    "\n",
    "new_model = keras.Model(\n",
    "    inputs=[title, text_body, tags],\n",
    "    outputs=[priority, department, difficulty])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(new_model, \"updated_ticket_classifier.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Subclassing the Model class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Rewriting our previous example as a subclassed model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple subclassed model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomerTicketModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_departments):\n",
    "        super().__init__()\n",
    "        self.concat_layer = layers.Concatenate()\n",
    "        self.mixing_layer = layers.Dense(64, activation=\"relu\")\n",
    "        self.priority_scorer = layers.Dense(1, activation=\"sigmoid\")\n",
    "        self.department_classifier = layers.Dense(\n",
    "            num_departments, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        title = inputs[\"title\"]\n",
    "        text_body = inputs[\"text_body\"]\n",
    "        tags = inputs[\"tags\"]\n",
    "\n",
    "        features = self.concat_layer([title, text_body, tags])\n",
    "        features = self.mixing_layer(features)\n",
    "        priority = self.priority_scorer(features)\n",
    "        department = self.department_classifier(features)\n",
    "        return priority, department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = CustomerTicketModel(num_departments=4)\n",
    "\n",
    "priority, department = model(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 13ms/step - loss: 39.5464 - output_1_loss: 0.3441 - output_2_loss: 39.2023 - output_1_mean_absolute_error: 0.5091 - output_2_accuracy: 0.2281\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 32.2440 - output_1_loss: 0.3517 - output_2_loss: 31.8923 - output_1_mean_absolute_error: 0.5168 - output_2_accuracy: 0.0664\n",
      "40/40 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit({\"title\": title_data,\n",
    "           \"text_body\": text_body_data,\n",
    "           \"tags\": tags_data},\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data,\n",
    "                \"text_body\": text_body_data,\n",
    "                \"tags\": tags_data},\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict({\"title\": title_data,\n",
    "                                                  \"text_body\": text_body_data,\n",
    "                                                  \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Beware: What subclassed models don't support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Mixing and matching different components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a Functional model that includes a subclassed model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class Classifier(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        if num_classes == 2:\n",
    "            num_units = 1\n",
    "            activation = \"sigmoid\"\n",
    "        else:\n",
    "            num_units = num_classes\n",
    "            activation = \"softmax\"\n",
    "        self.dense = layers.Dense(num_units, activation=activation)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.dense(inputs)\n",
    "\n",
    "inputs = keras.Input(shape=(3,))\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = Classifier(num_classes=10)(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a subclassed model that includes a Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(64,))\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(inputs)\n",
    "binary_classifier = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "class MyModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.dense = layers.Dense(64, activation=\"relu\")\n",
    "        self.classifier = binary_classifier\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features = self.dense(inputs)\n",
    "        return self.classifier(features)\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Remember: Use the right tool for the job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Using built-in training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The standard workflow: `compile()`, `fit()`, `evaluate()`, `predict()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2932 - accuracy: 0.9133 - val_loss: 0.1524 - val_accuracy: 0.9580\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1637 - accuracy: 0.9545 - val_loss: 0.1182 - val_accuracy: 0.9683\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1404 - accuracy: 0.9628 - val_loss: 0.1119 - val_accuracy: 0.9711\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1088 - accuracy: 0.9711\n",
      "313/313 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "def get_mnist_model():\n",
    "    inputs = keras.Input(shape=(28 * 28,))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]\n",
    "\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom metric by subclassing the `Metric` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class RootMeanSquaredError(keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self, name=\"rmse\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(\n",
    "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])\n",
    "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "        self.mse_sum.assign_add(mse)\n",
    "        num_samples = tf.shape(y_pred)[0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "\n",
    "    def result(self):\n",
    "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2928 - accuracy: 0.9145 - rmse: 7.1824 - val_loss: 0.1504 - val_accuracy: 0.9616 - val_rmse: 7.3625\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1659 - accuracy: 0.9535 - rmse: 7.3543 - val_loss: 0.1207 - val_accuracy: 0.9663 - val_rmse: 7.4009\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1400 - accuracy: 0.9624 - rmse: 7.3887 - val_loss: 0.1218 - val_accuracy: 0.9707 - val_rmse: 7.4250\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1017 - accuracy: 0.9747 - rmse: 7.4389\n"
     ]
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\", RootMeanSquaredError()])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Using callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The EarlyStopping and ModelCheckpoint callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Using the `callbacks` argument in the `fit()` method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2924 - accuracy: 0.9136 - val_loss: 0.1461 - val_accuracy: 0.9589\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1660 - accuracy: 0.9534 - val_loss: 0.1196 - val_accuracy: 0.9684\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1409 - accuracy: 0.9628 - val_loss: 0.1124 - val_accuracy: 0.9715\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1254 - accuracy: 0.9669 - val_loss: 0.1148 - val_accuracy: 0.9724\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1167 - accuracy: 0.9703 - val_loss: 0.1098 - val_accuracy: 0.9766\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1152 - accuracy: 0.9720 - val_loss: 0.1060 - val_accuracy: 0.9778\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1054 - accuracy: 0.9748 - val_loss: 0.1178 - val_accuracy: 0.9768\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1004 - accuracy: 0.9765 - val_loss: 0.1107 - val_accuracy: 0.9776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7e1cfc5df0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=2,\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"checkpoint_path.keras\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "    )\n",
    "]\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"checkpoint_path.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a custom callback by subclassing the `Callback` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        self.per_batch_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        plt.clf()\n",
    "        plt.plot(range(len(self.per_batch_losses)), self.per_batch_losses,\n",
    "                 label=\"Training loss for each batch\")\n",
    "        plt.xlabel(f\"Batch (epoch {epoch})\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"plot_at_epoch_{epoch}\")\n",
    "        self.per_batch_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2966 - accuracy: 0.9122 - val_loss: 0.1585 - val_accuracy: 0.9526\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1675 - accuracy: 0.9530 - val_loss: 0.1254 - val_accuracy: 0.9655\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1436 - accuracy: 0.9618 - val_loss: 0.1163 - val_accuracy: 0.9688\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1283 - accuracy: 0.9676 - val_loss: 0.1087 - val_accuracy: 0.9743\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1177 - accuracy: 0.9702 - val_loss: 0.1152 - val_accuracy: 0.9741\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1103 - accuracy: 0.9724 - val_loss: 0.1119 - val_accuracy: 0.9743\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1060 - accuracy: 0.9744 - val_loss: 0.1166 - val_accuracy: 0.9772\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1016 - accuracy: 0.9764 - val_loss: 0.1167 - val_accuracy: 0.9764\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1023 - accuracy: 0.9770 - val_loss: 0.1161 - val_accuracy: 0.9775\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0954 - accuracy: 0.9786 - val_loss: 0.1167 - val_accuracy: 0.9778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7e1d5cba60>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=[LossHistory()],\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Monitoring and visualization with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-30 18:41:57.835083: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at summary_kernels.cc:65 : PERMISSION_DENIED: /full_path_to_your_log_dir; Read-only file system\n"
     ]
    },
    {
     "ename": "PermissionDeniedError",
     "evalue": "{{function_node __wrapped__CreateSummaryFileWriter_device_/job:localhost/replica:0/task:0/device:CPU:0}} /full_path_to_your_log_dir; Read-only file system [Op:CreateSummaryFileWriter]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionDeniedError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ry/phxc250s3lx_m2h646xkjb1h0000gn/T/ipykernel_6294/87661999.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/full_path_to_your_log_dir\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m----> 9\u001b[0;31m model.fit(train_images, train_labels,\n\u001b[0m\u001b[1;32m     10\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7207\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7208\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7209\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionDeniedError\u001b[0m: {{function_node __wrapped__CreateSummaryFileWriter_device_/job:localhost/replica:0/task:0/device:CPU:0}} /full_path_to_your_log_dir; Read-only file system [Op:CreateSummaryFileWriter]"
     ]
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "    log_dir=\"/full_path_to_your_log_dir\",\n",
    ")\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          validation_data=(val_images, val_labels),\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /full_path_to_your_log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Writing your own training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Training versus inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Low-level usage of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "targets = [0, 1, 2]\n",
    "predictions = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "metric.update_state(targets, predictions)\n",
    "current_result = metric.result()\n",
    "print(f\"result: {current_result:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "values = [0, 1, 2, 3, 4]\n",
    "mean_tracker = keras.metrics.Mean()\n",
    "for value in values:\n",
    "    mean_tracker.update_state(value)\n",
    "print(f\"Mean of values: {mean_tracker.result():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### A complete training and evaluation loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the training step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.RMSprop()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "loss_tracking_metric = keras.metrics.Mean()\n",
    "\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"loss\"] = loss_tracking_metric.result()\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: resetting the metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def reset_metrics():\n",
    "    for metric in metrics:\n",
    "        metric.reset_state()\n",
    "    loss_tracking_metric.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the loop itself**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "training_dataset = training_dataset.batch(32)\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    reset_metrics()\n",
    "    for inputs_batch, targets_batch in training_dataset:\n",
    "        logs = train_step(inputs_batch, targets_batch)\n",
    "    print(f\"Results at the end of epoch {epoch}\")\n",
    "    for key, value in logs.items():\n",
    "        print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step evaluation loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Make it fast with tf.function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Adding a `tf.function` decorator to our evaluation-step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Leveraging fit() with a custom training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom training step to use with `fit()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = loss_fn(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "\n",
    "        loss_tracker.update_state(loss)\n",
    "        return {\"loss\": loss_tracker.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop())\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = self.compiled_loss(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "        self.compiled_metrics.update_state(targets, predictions)\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Summary"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter07_working-with-keras.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
