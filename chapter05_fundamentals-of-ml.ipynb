{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
    "\n",
    "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
    "\n",
    "This notebook was generated for TensorFlow 2.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Fundamentals of machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Generalization: The goal of machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Underfitting and overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Noisy training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Ambiguous features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Rare features and spurious correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Adding white-noise channels or all-zeros channels to MNIST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-23 16:21:13.006547: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(train_images, train_labels), _ = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "\n",
    "train_images_with_noise_channels = np.concatenate(\n",
    "    [train_images, np.random.random((len(train_images), 784))], axis=1)\n",
    "\n",
    "train_images_with_zeros_channels = np.concatenate(\n",
    "    [train_images, np.zeros((len(train_images), 784))], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training the same model on MNIST data with noise channels or all-zero channels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-23 16:21:23.377548: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.6230 - accuracy: 0.8125 - val_loss: 0.2482 - val_accuracy: 0.9283\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2505 - accuracy: 0.9233 - val_loss: 0.1935 - val_accuracy: 0.9449\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1628 - accuracy: 0.9500 - val_loss: 0.2007 - val_accuracy: 0.9377\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1144 - accuracy: 0.9647 - val_loss: 0.1927 - val_accuracy: 0.9416\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0833 - accuracy: 0.9739 - val_loss: 0.1325 - val_accuracy: 0.9621\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0616 - accuracy: 0.9802 - val_loss: 0.2335 - val_accuracy: 0.9367\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0467 - accuracy: 0.9847 - val_loss: 0.1193 - val_accuracy: 0.9681\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0340 - accuracy: 0.9894 - val_loss: 0.1984 - val_accuracy: 0.9485\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0259 - accuracy: 0.9919 - val_loss: 0.1287 - val_accuracy: 0.9687\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.0203 - accuracy: 0.9936 - val_loss: 0.1328 - val_accuracy: 0.9695\n",
      "Epoch 1/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.2872 - accuracy: 0.9174 - val_loss: 0.1800 - val_accuracy: 0.9459\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.1207 - accuracy: 0.9644 - val_loss: 0.1057 - val_accuracy: 0.9682\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0788 - accuracy: 0.9767 - val_loss: 0.0941 - val_accuracy: 0.9719\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0573 - accuracy: 0.9828 - val_loss: 0.0835 - val_accuracy: 0.9751\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.0430 - accuracy: 0.9868 - val_loss: 0.0888 - val_accuracy: 0.9725\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0325 - accuracy: 0.9903 - val_loss: 0.0811 - val_accuracy: 0.9765\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.0242 - accuracy: 0.9931 - val_loss: 0.0893 - val_accuracy: 0.9760\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.0181 - accuracy: 0.9948 - val_loss: 0.0812 - val_accuracy: 0.9787\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0143 - accuracy: 0.9960 - val_loss: 0.0785 - val_accuracy: 0.9793\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0101 - accuracy: 0.9972 - val_loss: 0.0841 - val_accuracy: 0.9773\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def get_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(512, activation=\"relu\"),\n",
    "        layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "    model.compile(optimizer=\"rmsprop\",\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "history_noise = model.fit(\n",
    "    train_images_with_noise_channels, train_labels,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)\n",
    "\n",
    "model = get_model()\n",
    "history_zeros = model.fit(\n",
    "    train_images_with_zeros_channels, train_labels,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Plotting a validation accuracy comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fcdf8e24af0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "val_acc_noise = history_noise.history[\"val_accuracy\"]\n",
    "val_acc_zeros = history_zeros.history[\"val_accuracy\"]\n",
    "epochs = range(1, 11)\n",
    "plt.plot(epochs, val_acc_noise, \"b-\",\n",
    "         label=\"Validation accuracy with noise channels\")\n",
    "plt.plot(epochs, val_acc_zeros, \"b--\",\n",
    "         label=\"Validation accuracy with zeros channels\")\n",
    "plt.title(\"Effect of noise channels on validation accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The nature of generalization in deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Fitting a MNIST model with randomly shuffled labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "375/375 [==============================] - 3s 6ms/step - loss: 2.3178 - accuracy: 0.0998 - val_loss: 2.3064 - val_accuracy: 0.0992\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.2994 - accuracy: 0.1181 - val_loss: 2.3124 - val_accuracy: 0.0970\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 2.2888 - accuracy: 0.1280 - val_loss: 2.3215 - val_accuracy: 0.1057\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.2739 - accuracy: 0.1408 - val_loss: 2.3270 - val_accuracy: 0.1052\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2550 - accuracy: 0.1559 - val_loss: 2.3434 - val_accuracy: 0.1007\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2333 - accuracy: 0.1728 - val_loss: 2.3563 - val_accuracy: 0.1035\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 2.2078 - accuracy: 0.1884 - val_loss: 2.3779 - val_accuracy: 0.1068\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.1791 - accuracy: 0.2018 - val_loss: 2.3941 - val_accuracy: 0.1002\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.1480 - accuracy: 0.2193 - val_loss: 2.4168 - val_accuracy: 0.1008\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.1156 - accuracy: 0.2354 - val_loss: 2.4318 - val_accuracy: 0.1020\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.0821 - accuracy: 0.2512 - val_loss: 2.4598 - val_accuracy: 0.0997\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.0477 - accuracy: 0.2666 - val_loss: 2.4814 - val_accuracy: 0.1020\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.0132 - accuracy: 0.2822 - val_loss: 2.5079 - val_accuracy: 0.1020\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.9776 - accuracy: 0.2985 - val_loss: 2.5434 - val_accuracy: 0.0999\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.9432 - accuracy: 0.3110 - val_loss: 2.5849 - val_accuracy: 0.1022\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.9072 - accuracy: 0.3281 - val_loss: 2.6161 - val_accuracy: 0.1049\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.8725 - accuracy: 0.3422 - val_loss: 2.6360 - val_accuracy: 0.0998\n",
      "Epoch 18/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.8381 - accuracy: 0.3552 - val_loss: 2.6655 - val_accuracy: 0.1005\n",
      "Epoch 19/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.8028 - accuracy: 0.3693 - val_loss: 2.7333 - val_accuracy: 0.1060\n",
      "Epoch 20/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.7725 - accuracy: 0.3843 - val_loss: 2.7459 - val_accuracy: 0.1016\n",
      "Epoch 21/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.7372 - accuracy: 0.3957 - val_loss: 2.7770 - val_accuracy: 0.1007\n",
      "Epoch 22/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.7061 - accuracy: 0.4065 - val_loss: 2.8235 - val_accuracy: 0.1022\n",
      "Epoch 23/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.6738 - accuracy: 0.4202 - val_loss: 2.8763 - val_accuracy: 0.1021\n",
      "Epoch 24/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.6440 - accuracy: 0.4323 - val_loss: 2.9129 - val_accuracy: 0.1032\n",
      "Epoch 25/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.6144 - accuracy: 0.4411 - val_loss: 2.9785 - val_accuracy: 0.1012\n",
      "Epoch 26/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.5836 - accuracy: 0.4562 - val_loss: 2.9936 - val_accuracy: 0.1011\n",
      "Epoch 27/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.5588 - accuracy: 0.4660 - val_loss: 3.0561 - val_accuracy: 0.1023\n",
      "Epoch 28/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.5278 - accuracy: 0.4763 - val_loss: 3.0683 - val_accuracy: 0.1014\n",
      "Epoch 29/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.5017 - accuracy: 0.4852 - val_loss: 3.1130 - val_accuracy: 0.1015\n",
      "Epoch 30/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.4748 - accuracy: 0.4952 - val_loss: 3.1754 - val_accuracy: 0.0985\n",
      "Epoch 31/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.4502 - accuracy: 0.5031 - val_loss: 3.2196 - val_accuracy: 0.1068\n",
      "Epoch 32/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.4248 - accuracy: 0.5139 - val_loss: 3.2715 - val_accuracy: 0.1028\n",
      "Epoch 33/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.3990 - accuracy: 0.5247 - val_loss: 3.2984 - val_accuracy: 0.1047\n",
      "Epoch 34/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.3742 - accuracy: 0.5296 - val_loss: 3.3646 - val_accuracy: 0.1021\n",
      "Epoch 35/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.3524 - accuracy: 0.5421 - val_loss: 3.4141 - val_accuracy: 0.1032\n",
      "Epoch 36/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.3279 - accuracy: 0.5470 - val_loss: 3.4990 - val_accuracy: 0.1005\n",
      "Epoch 37/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.3072 - accuracy: 0.5561 - val_loss: 3.5295 - val_accuracy: 0.1057\n",
      "Epoch 38/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.2826 - accuracy: 0.5647 - val_loss: 3.5588 - val_accuracy: 0.1042\n",
      "Epoch 39/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.2620 - accuracy: 0.5750 - val_loss: 3.6097 - val_accuracy: 0.1023\n",
      "Epoch 40/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.2416 - accuracy: 0.5812 - val_loss: 3.6651 - val_accuracy: 0.1028\n",
      "Epoch 41/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.2199 - accuracy: 0.5881 - val_loss: 3.7224 - val_accuracy: 0.1006\n",
      "Epoch 42/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.1995 - accuracy: 0.5952 - val_loss: 3.7497 - val_accuracy: 0.1072\n",
      "Epoch 43/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.1802 - accuracy: 0.6022 - val_loss: 3.8110 - val_accuracy: 0.1031\n",
      "Epoch 44/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.1592 - accuracy: 0.6090 - val_loss: 3.8817 - val_accuracy: 0.1050\n",
      "Epoch 45/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.1401 - accuracy: 0.6151 - val_loss: 3.9207 - val_accuracy: 0.1017\n",
      "Epoch 46/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.1218 - accuracy: 0.6242 - val_loss: 3.9637 - val_accuracy: 0.1021\n",
      "Epoch 47/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.1026 - accuracy: 0.6307 - val_loss: 4.0279 - val_accuracy: 0.1004\n",
      "Epoch 48/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.0865 - accuracy: 0.6359 - val_loss: 4.1122 - val_accuracy: 0.1022\n",
      "Epoch 49/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.0686 - accuracy: 0.6416 - val_loss: 4.2020 - val_accuracy: 0.1047\n",
      "Epoch 50/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.0510 - accuracy: 0.6476 - val_loss: 4.2007 - val_accuracy: 0.1018\n",
      "Epoch 51/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.0338 - accuracy: 0.6558 - val_loss: 4.2318 - val_accuracy: 0.1018\n",
      "Epoch 52/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.0183 - accuracy: 0.6600 - val_loss: 4.3175 - val_accuracy: 0.1012\n",
      "Epoch 53/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.0039 - accuracy: 0.6639 - val_loss: 4.3728 - val_accuracy: 0.1018\n",
      "Epoch 54/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.9849 - accuracy: 0.6709 - val_loss: 4.4382 - val_accuracy: 0.1022\n",
      "Epoch 55/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.9716 - accuracy: 0.6767 - val_loss: 4.4896 - val_accuracy: 0.1047\n",
      "Epoch 56/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9559 - accuracy: 0.6834 - val_loss: 4.5503 - val_accuracy: 0.1009\n",
      "Epoch 57/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9404 - accuracy: 0.6873 - val_loss: 4.6233 - val_accuracy: 0.1011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9270 - accuracy: 0.6917 - val_loss: 4.6702 - val_accuracy: 0.1055\n",
      "Epoch 59/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9112 - accuracy: 0.6964 - val_loss: 4.7616 - val_accuracy: 0.1034\n",
      "Epoch 60/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8994 - accuracy: 0.7021 - val_loss: 4.7703 - val_accuracy: 0.1019\n",
      "Epoch 61/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8831 - accuracy: 0.7060 - val_loss: 4.8795 - val_accuracy: 0.1028\n",
      "Epoch 62/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8692 - accuracy: 0.7138 - val_loss: 4.9032 - val_accuracy: 0.1032\n",
      "Epoch 63/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8559 - accuracy: 0.7168 - val_loss: 4.9722 - val_accuracy: 0.1027\n",
      "Epoch 64/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8431 - accuracy: 0.7195 - val_loss: 5.0115 - val_accuracy: 0.1014\n",
      "Epoch 65/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8332 - accuracy: 0.7226 - val_loss: 5.1043 - val_accuracy: 0.1028\n",
      "Epoch 66/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8173 - accuracy: 0.7300 - val_loss: 5.1446 - val_accuracy: 0.1023\n",
      "Epoch 67/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.8046 - accuracy: 0.7335 - val_loss: 5.2470 - val_accuracy: 0.1043\n",
      "Epoch 68/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7944 - accuracy: 0.7371 - val_loss: 5.2733 - val_accuracy: 0.1034\n",
      "Epoch 69/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7822 - accuracy: 0.7422 - val_loss: 5.3302 - val_accuracy: 0.0997\n",
      "Epoch 70/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7678 - accuracy: 0.7473 - val_loss: 5.3993 - val_accuracy: 0.1022\n",
      "Epoch 71/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.7559 - accuracy: 0.7508 - val_loss: 5.4530 - val_accuracy: 0.1028\n",
      "Epoch 72/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7470 - accuracy: 0.7535 - val_loss: 5.6004 - val_accuracy: 0.0997\n",
      "Epoch 73/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7350 - accuracy: 0.7583 - val_loss: 5.5997 - val_accuracy: 0.1011\n",
      "Epoch 74/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7237 - accuracy: 0.7632 - val_loss: 5.6952 - val_accuracy: 0.1010\n",
      "Epoch 75/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7131 - accuracy: 0.7647 - val_loss: 5.7115 - val_accuracy: 0.1023\n",
      "Epoch 76/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7006 - accuracy: 0.7707 - val_loss: 5.8170 - val_accuracy: 0.1022\n",
      "Epoch 77/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6912 - accuracy: 0.7744 - val_loss: 5.8350 - val_accuracy: 0.1016\n",
      "Epoch 78/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6822 - accuracy: 0.7760 - val_loss: 5.9217 - val_accuracy: 0.1039\n",
      "Epoch 79/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6729 - accuracy: 0.7792 - val_loss: 5.9733 - val_accuracy: 0.1013\n",
      "Epoch 80/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6607 - accuracy: 0.7820 - val_loss: 6.0565 - val_accuracy: 0.1022\n",
      "Epoch 81/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6507 - accuracy: 0.7868 - val_loss: 6.1044 - val_accuracy: 0.1013\n",
      "Epoch 82/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6409 - accuracy: 0.7910 - val_loss: 6.1762 - val_accuracy: 0.1028\n",
      "Epoch 83/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6307 - accuracy: 0.7948 - val_loss: 6.2407 - val_accuracy: 0.1013\n",
      "Epoch 84/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6241 - accuracy: 0.7976 - val_loss: 6.2980 - val_accuracy: 0.1038\n",
      "Epoch 85/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6161 - accuracy: 0.7994 - val_loss: 6.4225 - val_accuracy: 0.1011\n",
      "Epoch 86/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6046 - accuracy: 0.8027 - val_loss: 6.4502 - val_accuracy: 0.0995\n",
      "Epoch 87/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5970 - accuracy: 0.8063 - val_loss: 6.5583 - val_accuracy: 0.1006\n",
      "Epoch 88/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5861 - accuracy: 0.8098 - val_loss: 6.6210 - val_accuracy: 0.0997\n",
      "Epoch 89/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5779 - accuracy: 0.8111 - val_loss: 6.6715 - val_accuracy: 0.0997\n",
      "Epoch 90/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5703 - accuracy: 0.8158 - val_loss: 6.7155 - val_accuracy: 0.1007\n",
      "Epoch 91/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5603 - accuracy: 0.8175 - val_loss: 6.7732 - val_accuracy: 0.1030\n",
      "Epoch 92/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5527 - accuracy: 0.8209 - val_loss: 6.8992 - val_accuracy: 0.0987\n",
      "Epoch 93/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5443 - accuracy: 0.8238 - val_loss: 6.9526 - val_accuracy: 0.1016\n",
      "Epoch 94/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5384 - accuracy: 0.8257 - val_loss: 6.9839 - val_accuracy: 0.1029\n",
      "Epoch 95/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.5295 - accuracy: 0.8288 - val_loss: 7.0353 - val_accuracy: 0.1026\n",
      "Epoch 96/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5212 - accuracy: 0.8324 - val_loss: 7.1503 - val_accuracy: 0.1007\n",
      "Epoch 97/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5138 - accuracy: 0.8345 - val_loss: 7.2626 - val_accuracy: 0.1005\n",
      "Epoch 98/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5082 - accuracy: 0.8348 - val_loss: 7.2894 - val_accuracy: 0.1004\n",
      "Epoch 99/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5018 - accuracy: 0.8381 - val_loss: 7.3730 - val_accuracy: 0.1015\n",
      "Epoch 100/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4909 - accuracy: 0.8411 - val_loss: 7.4417 - val_accuracy: 0.1031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fce45726c70>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_images, train_labels), _ = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "\n",
    "random_train_labels = train_labels[:]\n",
    "np.random.shuffle(random_train_labels)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, random_train_labels,\n",
    "          epochs=100,\n",
    "          batch_size=128,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The manifold hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Interpolation as a source of generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Why deep learning works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Training data is paramount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Evaluating machine-learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Training, validation, and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Simple hold-out validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### K-fold validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Iterated K-fold validation with shuffling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Beating a common-sense baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Things to keep in mind about model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Improving model fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Tuning key gradient descent parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a MNIST model with an incorrectly high learning rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 756.5256 - accuracy: 0.4125 - val_loss: 2.2390 - val_accuracy: 0.2765\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 5.2917 - accuracy: 0.2896 - val_loss: 2.4425 - val_accuracy: 0.3296\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 3.5802 - accuracy: 0.2381 - val_loss: 2.1383 - val_accuracy: 0.2233\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 3.2493 - accuracy: 0.2364 - val_loss: 3.3666 - val_accuracy: 0.3092\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 4.2141 - accuracy: 0.2659 - val_loss: 4.0479 - val_accuracy: 0.2952\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.5228 - accuracy: 0.2397 - val_loss: 5.9107 - val_accuracy: 0.2441\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.8354 - accuracy: 0.2634 - val_loss: 2.0190 - val_accuracy: 0.2443\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3932 - accuracy: 0.2540 - val_loss: 2.9257 - val_accuracy: 0.2924\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.6802 - accuracy: 0.2856 - val_loss: 2.0478 - val_accuracy: 0.2847\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.4106 - accuracy: 0.2741 - val_loss: 3.8910 - val_accuracy: 0.3870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fce05a13c70>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_images, train_labels), _ = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(1.),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          batch_size=128,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The same model with a more appropriate learning rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 0.3447 - accuracy: 0.9133 - val_loss: 0.1755 - val_accuracy: 0.9483\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1387 - accuracy: 0.9645 - val_loss: 0.1616 - val_accuracy: 0.9615\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1147 - accuracy: 0.9730 - val_loss: 0.1648 - val_accuracy: 0.9703\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1013 - accuracy: 0.9771 - val_loss: 0.1851 - val_accuracy: 0.9728\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0875 - accuracy: 0.9816 - val_loss: 0.2055 - val_accuracy: 0.9713\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0804 - accuracy: 0.9841 - val_loss: 0.2094 - val_accuracy: 0.9747\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0735 - accuracy: 0.9853 - val_loss: 0.2250 - val_accuracy: 0.9728\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0625 - accuracy: 0.9880 - val_loss: 0.2906 - val_accuracy: 0.9725\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0624 - accuracy: 0.9886 - val_loss: 0.3394 - val_accuracy: 0.9681\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0610 - accuracy: 0.9897 - val_loss: 0.2750 - val_accuracy: 0.9753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcdf947b850>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(1e-2),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          batch_size=128,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Leveraging better architecture priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Increasing model capacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple logistic regression on MNIST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6602 - accuracy: 0.8406 - val_loss: 0.3599 - val_accuracy: 0.9027\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3499 - accuracy: 0.9039 - val_loss: 0.3067 - val_accuracy: 0.9147\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3148 - accuracy: 0.9125 - val_loss: 0.2906 - val_accuracy: 0.9176\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2989 - accuracy: 0.9171 - val_loss: 0.2802 - val_accuracy: 0.9218\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2893 - accuracy: 0.9184 - val_loss: 0.2765 - val_accuracy: 0.9232\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2827 - accuracy: 0.9210 - val_loss: 0.2715 - val_accuracy: 0.9250\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2779 - accuracy: 0.9223 - val_loss: 0.2687 - val_accuracy: 0.9277\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2739 - accuracy: 0.9243 - val_loss: 0.2663 - val_accuracy: 0.9272\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2714 - accuracy: 0.9246 - val_loss: 0.2666 - val_accuracy: 0.9266\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2684 - accuracy: 0.9253 - val_loss: 0.2643 - val_accuracy: 0.9290\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2667 - accuracy: 0.9266 - val_loss: 0.2641 - val_accuracy: 0.9287\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2645 - accuracy: 0.9271 - val_loss: 0.2629 - val_accuracy: 0.9285\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2633 - accuracy: 0.9279 - val_loss: 0.2630 - val_accuracy: 0.9296\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2615 - accuracy: 0.9280 - val_loss: 0.2619 - val_accuracy: 0.9300\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2602 - accuracy: 0.9286 - val_loss: 0.2606 - val_accuracy: 0.9312\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2589 - accuracy: 0.9290 - val_loss: 0.2614 - val_accuracy: 0.9298\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2581 - accuracy: 0.9298 - val_loss: 0.2601 - val_accuracy: 0.9327\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2570 - accuracy: 0.9293 - val_loss: 0.2617 - val_accuracy: 0.9314\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2563 - accuracy: 0.9300 - val_loss: 0.2613 - val_accuracy: 0.9296\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2555 - accuracy: 0.9299 - val_loss: 0.2610 - val_accuracy: 0.9317\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([layers.Dense(10, activation=\"softmax\")])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_small_model = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fcdf989f490>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "val_loss = history_small_model.history[\"val_loss\"]\n",
    "epochs = range(1, 21)\n",
    "plt.plot(epochs, val_loss, \"b--\",\n",
    "         label=\"Validation loss\")\n",
    "plt.title(\"Effect of insufficient model capacity on validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 0.3595 - accuracy: 0.8982 - val_loss: 0.1844 - val_accuracy: 0.9482\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1659 - accuracy: 0.9503 - val_loss: 0.1501 - val_accuracy: 0.9545\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1184 - accuracy: 0.9652 - val_loss: 0.1194 - val_accuracy: 0.9643\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0924 - accuracy: 0.9726 - val_loss: 0.1078 - val_accuracy: 0.9669\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0745 - accuracy: 0.9778 - val_loss: 0.1084 - val_accuracy: 0.9672\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0604 - accuracy: 0.9817 - val_loss: 0.0952 - val_accuracy: 0.9732\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0501 - accuracy: 0.9849 - val_loss: 0.0988 - val_accuracy: 0.9728\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0419 - accuracy: 0.9868 - val_loss: 0.1002 - val_accuracy: 0.9734\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0353 - accuracy: 0.9890 - val_loss: 0.0907 - val_accuracy: 0.9743\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0310 - accuracy: 0.9904 - val_loss: 0.1086 - val_accuracy: 0.9722\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0259 - accuracy: 0.9920 - val_loss: 0.1030 - val_accuracy: 0.9747\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0219 - accuracy: 0.9932 - val_loss: 0.1213 - val_accuracy: 0.9703\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0192 - accuracy: 0.9940 - val_loss: 0.1114 - val_accuracy: 0.9748\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0159 - accuracy: 0.9953 - val_loss: 0.1185 - val_accuracy: 0.9737\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.1271 - val_accuracy: 0.9713\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0124 - accuracy: 0.9966 - val_loss: 0.1246 - val_accuracy: 0.9733\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.1379 - val_accuracy: 0.9735\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.1325 - val_accuracy: 0.9754\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0077 - accuracy: 0.9978 - val_loss: 0.1372 - val_accuracy: 0.9753\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.1540 - val_accuracy: 0.9743\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(96, activation=\"relu\"),\n",
    "    layers.Dense(96, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_large_model = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Improving generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Dataset curation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Using early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Regularizing your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Reducing the network's size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Original model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 4s 92ms/step - loss: 0.5298 - accuracy: 0.7765 - val_loss: 0.3955 - val_accuracy: 0.8698\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 1s 36ms/step - loss: 0.3172 - accuracy: 0.9024 - val_loss: 0.3152 - val_accuracy: 0.8847\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.2288 - accuracy: 0.9299 - val_loss: 0.2828 - val_accuracy: 0.8908\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.1810 - accuracy: 0.9415 - val_loss: 0.2765 - val_accuracy: 0.8910\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.1484 - accuracy: 0.9538 - val_loss: 0.2902 - val_accuracy: 0.8852\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.1188 - accuracy: 0.9637 - val_loss: 0.3007 - val_accuracy: 0.8853\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0975 - accuracy: 0.9695 - val_loss: 0.3303 - val_accuracy: 0.8798\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0820 - accuracy: 0.9773 - val_loss: 0.3397 - val_accuracy: 0.8829\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.0694 - accuracy: 0.9803 - val_loss: 0.3958 - val_accuracy: 0.8692\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0562 - accuracy: 0.9851 - val_loss: 0.3892 - val_accuracy: 0.8777\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0473 - accuracy: 0.9889 - val_loss: 0.4381 - val_accuracy: 0.8704\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.0404 - accuracy: 0.9899 - val_loss: 0.4469 - val_accuracy: 0.8737\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0348 - accuracy: 0.9921 - val_loss: 0.4798 - val_accuracy: 0.8712\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0287 - accuracy: 0.9946 - val_loss: 0.4996 - val_accuracy: 0.8700\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.0283 - accuracy: 0.9929 - val_loss: 0.5317 - val_accuracy: 0.8687\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0157 - accuracy: 0.9980 - val_loss: 0.5931 - val_accuracy: 0.8605\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 0.0201 - accuracy: 0.9951 - val_loss: 0.5998 - val_accuracy: 0.8686\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.0100 - accuracy: 0.9990 - val_loss: 0.6148 - val_accuracy: 0.8650\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.0124 - accuracy: 0.9977 - val_loss: 0.6507 - val_accuracy: 0.8656\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.0088 - accuracy: 0.9989 - val_loss: 0.6922 - val_accuracy: 0.8656\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "(train_data, train_labels), _ = imdb.load_data(num_words=10000)\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "train_data = vectorize_sequences(train_data)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_original = model.fit(train_data, train_labels,\n",
    "                             epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Version of the model with lower capacity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 4s 89ms/step - loss: 0.6589 - accuracy: 0.6025 - val_loss: 0.6292 - val_accuracy: 0.6389\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 1s 31ms/step - loss: 0.6015 - accuracy: 0.7155 - val_loss: 0.5866 - val_accuracy: 0.7391\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.5571 - accuracy: 0.7760 - val_loss: 0.5529 - val_accuracy: 0.7735\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.5199 - accuracy: 0.8163 - val_loss: 0.5256 - val_accuracy: 0.8240\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.4888 - accuracy: 0.8497 - val_loss: 0.5044 - val_accuracy: 0.8240\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.4618 - accuracy: 0.8714 - val_loss: 0.4870 - val_accuracy: 0.8376\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.4383 - accuracy: 0.8905 - val_loss: 0.4710 - val_accuracy: 0.8677\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.4176 - accuracy: 0.9055 - val_loss: 0.4679 - val_accuracy: 0.8406\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.3990 - accuracy: 0.9156 - val_loss: 0.4548 - val_accuracy: 0.8589\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.3821 - accuracy: 0.9257 - val_loss: 0.4453 - val_accuracy: 0.8691\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.3664 - accuracy: 0.9343 - val_loss: 0.4443 - val_accuracy: 0.8644\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 0.3516 - accuracy: 0.9418 - val_loss: 0.4511 - val_accuracy: 0.8580\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 0.3383 - accuracy: 0.9476 - val_loss: 0.4327 - val_accuracy: 0.8751\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.3254 - accuracy: 0.9548 - val_loss: 0.4303 - val_accuracy: 0.8750\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.3134 - accuracy: 0.9597 - val_loss: 0.4339 - val_accuracy: 0.8742\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.3025 - accuracy: 0.9634 - val_loss: 0.4468 - val_accuracy: 0.8683\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.2917 - accuracy: 0.9675 - val_loss: 0.4447 - val_accuracy: 0.8710\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.2815 - accuracy: 0.9706 - val_loss: 0.4356 - val_accuracy: 0.8762\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.2722 - accuracy: 0.9739 - val_loss: 0.4475 - val_accuracy: 0.8727\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.2630 - accuracy: 0.9771 - val_loss: 0.4753 - val_accuracy: 0.8626\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(4, activation=\"relu\"),\n",
    "    layers.Dense(4, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_smaller_model = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Version of the model with higher capacity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "15/15 [==============================] - 4s 240ms/step - loss: 0.6571 - accuracy: 0.6983 - val_loss: 0.4631 - val_accuracy: 0.7794\n",
      "Epoch 2/20\n",
      "15/15 [==============================] - 2s 140ms/step - loss: 0.4078 - accuracy: 0.8319 - val_loss: 0.2956 - val_accuracy: 0.8873\n",
      "Epoch 3/20\n",
      "15/15 [==============================] - 2s 142ms/step - loss: 0.2841 - accuracy: 0.8966 - val_loss: 0.2690 - val_accuracy: 0.8934\n",
      "Epoch 4/20\n",
      "15/15 [==============================] - 3s 173ms/step - loss: 0.1675 - accuracy: 0.9393 - val_loss: 0.2776 - val_accuracy: 0.8954\n",
      "Epoch 5/20\n",
      "15/15 [==============================] - 2s 155ms/step - loss: 0.1227 - accuracy: 0.9533 - val_loss: 0.3141 - val_accuracy: 0.8857\n",
      "Epoch 6/20\n",
      "15/15 [==============================] - 3s 186ms/step - loss: 0.1361 - accuracy: 0.9513 - val_loss: 0.2771 - val_accuracy: 0.8901\n",
      "Epoch 7/20\n",
      "15/15 [==============================] - 2s 158ms/step - loss: 0.0204 - accuracy: 0.9976 - val_loss: 0.3819 - val_accuracy: 0.8899\n",
      "Epoch 8/20\n",
      "15/15 [==============================] - 2s 156ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 0.5030 - val_accuracy: 0.8834\n",
      "Epoch 9/20\n",
      "15/15 [==============================] - 2s 145ms/step - loss: 9.2529e-04 - accuracy: 0.9999 - val_loss: 0.5127 - val_accuracy: 0.8877\n",
      "Epoch 10/20\n",
      "15/15 [==============================] - 2s 136ms/step - loss: 2.3773e-04 - accuracy: 1.0000 - val_loss: 0.5654 - val_accuracy: 0.8865\n",
      "Epoch 11/20\n",
      "15/15 [==============================] - 2s 138ms/step - loss: 8.4625e-05 - accuracy: 1.0000 - val_loss: 0.6254 - val_accuracy: 0.8871\n",
      "Epoch 12/20\n",
      "15/15 [==============================] - 2s 135ms/step - loss: 3.4202e-05 - accuracy: 1.0000 - val_loss: 0.6701 - val_accuracy: 0.8872\n",
      "Epoch 13/20\n",
      "15/15 [==============================] - 2s 126ms/step - loss: 1.4791e-05 - accuracy: 1.0000 - val_loss: 0.7130 - val_accuracy: 0.8863\n",
      "Epoch 14/20\n",
      "15/15 [==============================] - 2s 127ms/step - loss: 6.6882e-06 - accuracy: 1.0000 - val_loss: 0.7540 - val_accuracy: 0.8862\n",
      "Epoch 15/20\n",
      "15/15 [==============================] - 2s 129ms/step - loss: 3.4774e-06 - accuracy: 1.0000 - val_loss: 0.8644 - val_accuracy: 0.8833\n",
      "Epoch 16/20\n",
      "15/15 [==============================] - 2s 127ms/step - loss: 0.8992 - accuracy: 0.9576 - val_loss: 0.6091 - val_accuracy: 0.8863\n",
      "Epoch 17/20\n",
      "15/15 [==============================] - 2s 129ms/step - loss: 3.5830e-05 - accuracy: 1.0000 - val_loss: 0.6154 - val_accuracy: 0.8861\n",
      "Epoch 18/20\n",
      "15/15 [==============================] - 2s 133ms/step - loss: 2.8555e-05 - accuracy: 1.0000 - val_loss: 0.6219 - val_accuracy: 0.8862\n",
      "Epoch 19/20\n",
      "15/15 [==============================] - 2s 135ms/step - loss: 2.3387e-05 - accuracy: 1.0000 - val_loss: 0.6278 - val_accuracy: 0.8858\n",
      "Epoch 20/20\n",
      "15/15 [==============================] - 2s 138ms/step - loss: 1.8403e-05 - accuracy: 1.0000 - val_loss: 0.6374 - val_accuracy: 0.8860\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_larger_model = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=1024, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Adding weight regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Adding L2 weight regularization to the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 3s 66ms/step - loss: 0.6077 - accuracy: 0.7729 - val_loss: 0.4832 - val_accuracy: 0.8696\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.4179 - accuracy: 0.8907 - val_loss: 0.3997 - val_accuracy: 0.8821\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.3438 - accuracy: 0.9127 - val_loss: 0.3684 - val_accuracy: 0.8883\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.3058 - accuracy: 0.9229 - val_loss: 0.3910 - val_accuracy: 0.8707\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2828 - accuracy: 0.9315 - val_loss: 0.3813 - val_accuracy: 0.8761\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 0.2691 - accuracy: 0.9375 - val_loss: 0.3601 - val_accuracy: 0.8863\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.2568 - accuracy: 0.9404 - val_loss: 0.3671 - val_accuracy: 0.8834\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.2515 - accuracy: 0.9406 - val_loss: 0.4105 - val_accuracy: 0.8671\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2413 - accuracy: 0.9453 - val_loss: 0.3675 - val_accuracy: 0.8824\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2375 - accuracy: 0.9463 - val_loss: 0.3735 - val_accuracy: 0.8800\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2322 - accuracy: 0.9489 - val_loss: 0.4057 - val_accuracy: 0.8702\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2313 - accuracy: 0.9473 - val_loss: 0.4200 - val_accuracy: 0.8678\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.2204 - accuracy: 0.9542 - val_loss: 0.4021 - val_accuracy: 0.8758\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.2240 - accuracy: 0.9506 - val_loss: 0.3913 - val_accuracy: 0.8766\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.2148 - accuracy: 0.9560 - val_loss: 0.4148 - val_accuracy: 0.8734\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2173 - accuracy: 0.9537 - val_loss: 0.4750 - val_accuracy: 0.8567\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.2132 - accuracy: 0.9542 - val_loss: 0.4092 - val_accuracy: 0.8763\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.2093 - accuracy: 0.9568 - val_loss: 0.4058 - val_accuracy: 0.8754\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.2127 - accuracy: 0.9550 - val_loss: 0.4390 - val_accuracy: 0.8675\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.2012 - accuracy: 0.9605 - val_loss: 0.4107 - val_accuracy: 0.8739\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(16,\n",
    "                 kernel_regularizer=regularizers.l2(0.002),\n",
    "                 activation=\"relu\"),\n",
    "    layers.Dense(16,\n",
    "                 kernel_regularizer=regularizers.l2(0.002),\n",
    "                 activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_l2_reg = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Different weight regularizers available in Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.regularizers.L1L2 at 0x7fce038d1a00>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "regularizers.l1(0.001)\n",
    "regularizers.l1_l2(l1=0.001, l2=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Adding dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Adding dropout to the IMDB model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 3s 71ms/step - loss: 0.6254 - accuracy: 0.6475 - val_loss: 0.5096 - val_accuracy: 0.8555\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.4988 - accuracy: 0.7773 - val_loss: 0.3993 - val_accuracy: 0.8652\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.4157 - accuracy: 0.8366 - val_loss: 0.3310 - val_accuracy: 0.8847\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.3560 - accuracy: 0.8699 - val_loss: 0.3035 - val_accuracy: 0.8884\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.3178 - accuracy: 0.8892 - val_loss: 0.2887 - val_accuracy: 0.8868\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2740 - accuracy: 0.9118 - val_loss: 0.2760 - val_accuracy: 0.8933\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 0.2476 - accuracy: 0.9227 - val_loss: 0.2889 - val_accuracy: 0.8886\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.2123 - accuracy: 0.9333 - val_loss: 0.2920 - val_accuracy: 0.8856\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.1901 - accuracy: 0.9400 - val_loss: 0.2985 - val_accuracy: 0.8916\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.1694 - accuracy: 0.9489 - val_loss: 0.3179 - val_accuracy: 0.8912\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.1552 - accuracy: 0.9520 - val_loss: 0.3645 - val_accuracy: 0.8858\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.1421 - accuracy: 0.9577 - val_loss: 0.3985 - val_accuracy: 0.8825\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.1270 - accuracy: 0.9621 - val_loss: 0.3823 - val_accuracy: 0.8869\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.1204 - accuracy: 0.9631 - val_loss: 0.4109 - val_accuracy: 0.8888\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.1034 - accuracy: 0.9695 - val_loss: 0.4184 - val_accuracy: 0.8855\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.1025 - accuracy: 0.9681 - val_loss: 0.4649 - val_accuracy: 0.8894\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0990 - accuracy: 0.9691 - val_loss: 0.4903 - val_accuracy: 0.8873\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0923 - accuracy: 0.9725 - val_loss: 0.5163 - val_accuracy: 0.8873\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0874 - accuracy: 0.9734 - val_loss: 0.5586 - val_accuracy: 0.8839\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0842 - accuracy: 0.9752 - val_loss: 0.5317 - val_accuracy: 0.8848\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_dropout = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Summary"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter05_fundamentals-of-ml.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
